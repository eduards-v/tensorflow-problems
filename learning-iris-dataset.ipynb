{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model with Iris dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#print(tf.__file__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow already have Iris dataset we can use to train our model.\n",
    "# Set contains 2 list:\n",
    "#     1) Length and width data for petal and sepal of each flower sample\n",
    "#     2) 3 dimensional vector of species types. \n",
    "#        Each specy is represented by 0, 1, 2 to be setosa, versicolor and virginica respectively.\n",
    "iris_set = tf.contrib.learn.datasets.load_iris()\n",
    "\n",
    "# print(iris_train.data)\n",
    "# print(iris_train.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[4 5 2 3 1]\n",
      "[14 15 12 13 11]\n"
     ]
    }
   ],
   "source": [
    "# Simple example of how to shuffle elemnts in 2 arrays of the same length  \n",
    "# and maintain shuffle order for both.\n",
    "# Adopted from https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "\n",
    "arr1 = [1, 2, 3, 4, 5]\n",
    "arr2 = [11, 12, 13, 14, 15]\n",
    "\n",
    "arr1 =  np.array(arr1)\n",
    "arr2 =  np.array(arr2)\n",
    "# list of indexes equal to the length of target array\n",
    "randomize = np.arange(len(arr1))\n",
    "print(randomize)\n",
    "# shuffle it\n",
    "np.random.shuffle(randomize)\n",
    "\n",
    "# set a new index order for both arrays\n",
    "arr1 = arr1[randomize]\n",
    "arr2 = arr2[randomize]\n",
    "\n",
    "print(arr1)\n",
    "print(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle data to randomly pick train and test sets \n",
    "# to train and test model.\n",
    "\n",
    "data = iris_set.data\n",
    "target = iris_set.target\n",
    " \n",
    "randomize = np.arange(len(data))\n",
    "np.random.shuffle(randomize)\n",
    "data = data[randomize]\n",
    "target = target[randomize]\n",
    "\n",
    "# split iris data and target arrays into training and test arrays\n",
    "# adopted from: https://github.com/emerging-technologies/keras-iris/blob/master/iris_nn.py\n",
    "inds = np.random.permutation(len(data)) \n",
    "train_inds, test_inds = np.array_split(inds, 2) \n",
    "training_data, training_target = data[train_inds], target[train_inds]\n",
    "test_data, test_target  = data[test_inds],  target[test_inds]\n",
    "\n",
    "# feed twice less data, but use same amount of test data\n",
    "inds2 = np.random.permutation(len(training_data)) \n",
    "train_inds2, test_inds2 = np.array_split(inds2, 2)\n",
    "training_data2, training_target2 = training_data[train_inds2], training_target[train_inds2]\n",
    "\n",
    "\n",
    "#print(len(training_data2))\n",
    "# print(len(test_data))\n",
    "\n",
    "# print(training_data)\n",
    "# print(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './models/iris_model3', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./models/iris_model3\\model.ckpt-2\n",
      "INFO:tensorflow:Saving checkpoints for 3 into ./models/iris_model3\\model.ckpt.\n",
      "INFO:tensorflow:loss = 118.332, step = 3\n",
      "INFO:tensorflow:global_step/sec: 388.884\n",
      "INFO:tensorflow:loss = 11.9692, step = 103 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 642.229\n",
      "INFO:tensorflow:loss = 12.444, step = 203 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.692\n",
      "INFO:tensorflow:loss = 4.24492, step = 303 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.492\n",
      "INFO:tensorflow:loss = 7.58108, step = 403 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.038\n",
      "INFO:tensorflow:loss = 11.687, step = 503 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.247\n",
      "INFO:tensorflow:loss = 2.25285, step = 603 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.561\n",
      "INFO:tensorflow:loss = 3.85491, step = 703 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 535.979\n",
      "INFO:tensorflow:loss = 12.2309, step = 803 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 581.393\n",
      "INFO:tensorflow:loss = 8.39447, step = 903 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.653\n",
      "INFO:tensorflow:loss = 4.63347, step = 1003 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 657.791\n",
      "INFO:tensorflow:loss = 8.91612, step = 1103 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 587.766\n",
      "INFO:tensorflow:loss = 5.73625, step = 1203 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.294\n",
      "INFO:tensorflow:loss = 3.57513, step = 1303 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.816\n",
      "INFO:tensorflow:loss = 5.61202, step = 1403 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 642.234\n",
      "INFO:tensorflow:loss = 3.99187, step = 1503 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.635\n",
      "INFO:tensorflow:loss = 4.74007, step = 1603 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 600.495\n",
      "INFO:tensorflow:loss = 3.91289, step = 1703 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.374\n",
      "INFO:tensorflow:loss = 2.48404, step = 1803 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.586\n",
      "INFO:tensorflow:loss = 3.64625, step = 1903 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.841\n",
      "INFO:tensorflow:loss = 2.18807, step = 2003 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 597.786\n",
      "INFO:tensorflow:loss = 5.52928, step = 2103 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.233\n",
      "INFO:tensorflow:loss = 6.99383, step = 2203 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 568.185\n",
      "INFO:tensorflow:loss = 1.18803, step = 2303 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.19\n",
      "INFO:tensorflow:loss = 2.68193, step = 2403 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.751\n",
      "INFO:tensorflow:loss = 4.57312, step = 2503 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.441\n",
      "INFO:tensorflow:loss = 2.27675, step = 2603 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.885\n",
      "INFO:tensorflow:loss = 2.16489, step = 2703 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 612.516\n",
      "INFO:tensorflow:loss = 7.05977, step = 2803 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.823\n",
      "INFO:tensorflow:loss = 3.96055, step = 2903 (0.251 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3002 into ./models/iris_model3\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.92904.\n",
      "INFO:tensorflow:Starting evaluation at 2017-11-24-14:45:50\n",
      "INFO:tensorflow:Restoring parameters from ./models/iris_model3\\model.ckpt-3002\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-24-14:45:51\n",
      "INFO:tensorflow:Saving dict for global step 3002: accuracy = 0.973333, average_loss = 0.0549799, global_step = 3002, loss = 4.12349\n",
      "\n",
      "Test Accuracy: 0.973333\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./models/iris_model3\\model.ckpt-3002\n",
      "New Samples, Class Predictions:    [array([b'1'], dtype=object), array([b'2'], dtype=object), array([b'0'], dtype=object), array([b'2'], dtype=object), array([b'1'], dtype=object), array([b'0'], dtype=object)]\n",
      "\n",
      "[array([b'1'], dtype=object), array([b'2'], dtype=object), array([b'0'], dtype=object), array([b'2'], dtype=object), array([b'1'], dtype=object), array([b'0'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "# Code is adopted from tutorial: https://www.tensorflow.org/get_started/estimator\n",
    "\n",
    "\n",
    "# Specify that all features have real-value data. We specify that dimension of array in\n",
    "# a each row of dataset has shape of 4 i.e., 4 rows.\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[4])]\n",
    "\n",
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "# Estimator using the ProximalAdagradOptimizer optimizer with\n",
    "# regularization.\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                      hidden_units=[10, 20, 10],\n",
    "                                      n_classes=3,\n",
    "                                      model_dir=\"./models/iris_model3\")\n",
    "# Define the training inputs\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"x\": np.array(training_data)},\n",
    "  y=np.array(training_target),\n",
    "  num_epochs=None,\n",
    "  shuffle=True)\n",
    "\n",
    "# Train model.\n",
    "classifier.train(input_fn=train_input_fn, steps=3000)\n",
    "\n",
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"x\": np.array(test_data)},\n",
    "  y=np.array(test_target),\n",
    "  num_epochs=1,\n",
    "  shuffle=False)\n",
    "\n",
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "\n",
    "print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))\n",
    "\n",
    "# Classify new flower samples.\n",
    "new_samples = np.array(\n",
    "  [[6.4, 3.2, 4.5, 1.5],\n",
    "   [5.8, 3.1, 5.0, 1.7],\n",
    "   [4.6, 3.4, 1.4, 0.3],\n",
    "   [5.9, 3.0, 5.1, 1.8],\n",
    "   [4.9, 2.1, 2.3, 1.7],\n",
    "   [4.9, 2.1, 1.3, 1.8]], dtype=np.float32)\n",
    "\n",
    "# Set data to a model\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"x\": new_samples},\n",
    "  num_epochs=1,\n",
    "  shuffle=False)\n",
    "\n",
    "# Run another test with new flower samples model to get predictions\n",
    "predictions = list(classifier.predict(input_fn=predict_input_fn))\n",
    "predicted_classes = [p[\"classes\"] for p in predictions]\n",
    "\n",
    "print(\n",
    "  \"New Samples, Class Predictions:    {}\\n\"\n",
    "  .format(predicted_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['versicolor', 'virginica', 'setosa', 'virginica', 'versicolor', 'setosa']\n"
     ]
    }
   ],
   "source": [
    "# Transform predictions into something meaningful\n",
    "predictions = np.array(predicted_classes).astype(int)\n",
    "#flowers = ['setosa', 'versicolor', 'virginica']\n",
    "report = []\n",
    "\n",
    "for index, item in enumerate(predictions):\n",
    "    if(item == 0):\n",
    "        report.append('setosa') #flowers[0] \n",
    "    elif(item == 1):\n",
    "        report.append('versicolor') #flowers[1] \n",
    "    elif(item == 2):\n",
    "        report.append('virginica') #flowers[2]  \n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "After training model multiple times, we can see that loss estimates to around 4.5, which is still quite high.\n",
    "Accuracy of the test in most cases varies from 96 to 98 percents. In some rare cases accuracy was recorded at 100 percent, or at least exceeding 98.\n",
    "\n",
    "What can we do to minimize loss and improve accuracy rate? \n",
    "\n",
    "* Increase training set size.\n",
    "* Increase neural network size.\n",
    "* Increase number of training steps from 3k to 20k and see what happens. \n",
    "* Pick defferent optimizer\n",
    "\n",
    "Generally speaking, to improve certain algorithm learning rate,\n",
    "you need to practice with different parameters stated above.\n",
    "If results are not satisfying for algorithm you've picked\n",
    "for your model, you are free to choose other algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
