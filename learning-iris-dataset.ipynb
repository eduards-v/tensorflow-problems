{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model with Iris dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python\\python36\\lib\\site-packages\\tensorflow\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__file__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow already have Iris dataset we can use to train our model.\n",
    "# Set contains 2 list:\n",
    "#     1) Length and width data for petal and sepal of each flower sample\n",
    "#     2) 3 dimensional vector of species types. \n",
    "#        Each specy is represented by 0, 1, 2 to be setosa, versicolor and virginica respectively.\n",
    "iris_set = tf.contrib.learn.datasets.load_iris()\n",
    "\n",
    "# print(iris_train.data)\n",
    "# print(iris_train.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[2 1 3 5 4]\n",
      "[12 11 13 15 14]\n"
     ]
    }
   ],
   "source": [
    "# Simple example of how to shuffle elemnts in 2 arrays of the same length  \n",
    "# and maintain shuffle order for both.\n",
    "# Adopted from https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "\n",
    "arr1 = [1, 2, 3, 4, 5]\n",
    "arr2 = [11, 12, 13, 14, 15]\n",
    "\n",
    "arr1 =  np.array(arr1)\n",
    "arr2 =  np.array(arr2)\n",
    "# list of indexes equal to the length of target array\n",
    "randomize = np.arange(len(arr1))\n",
    "print(randomize)\n",
    "# shuffle it\n",
    "np.random.shuffle(randomize)\n",
    "\n",
    "# set a new index order for both arrays\n",
    "arr1 = arr1[randomize]\n",
    "arr2 = arr2[randomize]\n",
    "\n",
    "print(arr1)\n",
    "print(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "# Shuffle data to randomly pick train and test sets \n",
    "# to train and test model.\n",
    "\n",
    "data = iris_set.data\n",
    "target = iris_set.target\n",
    " \n",
    "randomize = np.arange(len(data))\n",
    "np.random.shuffle(randomize)\n",
    "data = data[randomize]\n",
    "target = target[randomize]\n",
    "\n",
    "inds = np.random.permutation(len(data))\n",
    "train_inds, test_inds = np.array_split(inds, 2)\n",
    "training_data, training_target = data[train_inds], target[train_inds]\n",
    "test_data, test_target  = data[test_inds],  target[test_inds]\n",
    "\n",
    "inds2 = np.random.permutation(len(training_data))\n",
    "train_inds2, test_inds2 = np.array_split(inds2, 2)\n",
    "training_data2, training_target2 = training_data[train_inds2], training_target[train_inds2]\n",
    "\n",
    "\n",
    "print(len(training_data2))\n",
    "# print(len(test_data))\n",
    "\n",
    "# print(training_data)\n",
    "# print(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './models/iris_model', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./models/iris_model\\model.ckpt-5000\n",
      "INFO:tensorflow:Saving checkpoints for 5001 into ./models/iris_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0304869, step = 5001\n",
      "INFO:tensorflow:global_step/sec: 365.466\n",
      "INFO:tensorflow:loss = 0.029474, step = 5101 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.908\n",
      "INFO:tensorflow:loss = 0.0320262, step = 5201 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 555.097\n",
      "INFO:tensorflow:loss = 0.0289238, step = 5301 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 600.226\n",
      "INFO:tensorflow:loss = 0.033098, step = 5401 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.633\n",
      "INFO:tensorflow:loss = 0.0306803, step = 5501 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 594.825\n",
      "INFO:tensorflow:loss = 0.0311801, step = 5601 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.31\n",
      "INFO:tensorflow:loss = 0.022394, step = 5701 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.723\n",
      "INFO:tensorflow:loss = 0.0238907, step = 5801 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.021\n",
      "INFO:tensorflow:loss = 0.0260535, step = 5901 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.032\n",
      "INFO:tensorflow:loss = 0.034753, step = 6001 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 576.643\n",
      "INFO:tensorflow:loss = 0.0300883, step = 6101 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 547.966\n",
      "INFO:tensorflow:loss = 0.0277097, step = 6201 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.03\n",
      "INFO:tensorflow:loss = 0.0258272, step = 6301 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.568\n",
      "INFO:tensorflow:loss = 0.0264842, step = 6401 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.681\n",
      "INFO:tensorflow:loss = 0.0278176, step = 6501 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.871\n",
      "INFO:tensorflow:loss = 0.0281837, step = 6601 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 562\n",
      "INFO:tensorflow:loss = 0.0233402, step = 6701 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 598.251\n",
      "INFO:tensorflow:loss = 0.0229533, step = 6801 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.107\n",
      "INFO:tensorflow:loss = 0.0228884, step = 6901 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.453\n",
      "INFO:tensorflow:loss = 0.0194755, step = 7001 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.143\n",
      "INFO:tensorflow:loss = 0.0264124, step = 7101 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.435\n",
      "INFO:tensorflow:loss = 0.0183107, step = 7201 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.614\n",
      "INFO:tensorflow:loss = 0.0217279, step = 7301 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.828\n",
      "INFO:tensorflow:loss = 0.0208099, step = 7401 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 572.202\n",
      "INFO:tensorflow:loss = 0.0204537, step = 7501 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 549.312\n",
      "INFO:tensorflow:loss = 0.019086, step = 7601 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 564.87\n",
      "INFO:tensorflow:loss = 0.0183583, step = 7701 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 564.313\n",
      "INFO:tensorflow:loss = 0.0191179, step = 7801 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.556\n",
      "INFO:tensorflow:loss = 0.0183112, step = 7901 (0.164 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into ./models/iris_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.018254.\n",
      "INFO:tensorflow:Starting evaluation at 2017-11-24-00:36:09\n",
      "INFO:tensorflow:Restoring parameters from ./models/iris_model\\model.ckpt-8000\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-24-00:36:09\n",
      "INFO:tensorflow:Saving dict for global step 8000: accuracy = 0.973333, average_loss = 0.135238, global_step = 8000, loss = 10.1429\n",
      "\n",
      "Test Accuracy: 0.973333\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./models/iris_model\\model.ckpt-8000\n",
      "New Samples, Class Predictions:    [array([b'1'], dtype=object), array([b'2'], dtype=object), array([b'0'], dtype=object), array([b'2'], dtype=object)]\n",
      "\n",
      "[array([b'1'], dtype=object), array([b'2'], dtype=object), array([b'0'], dtype=object), array([b'2'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "# Code is adopted from tutorial: https://www.tensorflow.org/get_started/estimator\n",
    "\n",
    "\n",
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[4])]\n",
    "\n",
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                      hidden_units=[10, 20, 10],\n",
    "                                      n_classes=3,\n",
    "                                      model_dir=\"./models/iris_model\")\n",
    "# Define the training inputs\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"x\": np.array(training_data2)},\n",
    "  y=np.array(training_target2),\n",
    "  num_epochs=None,\n",
    "  shuffle=True)\n",
    "\n",
    "# Train model.\n",
    "classifier.train(input_fn=train_input_fn, steps=3000)\n",
    "\n",
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"x\": np.array(test_data)},\n",
    "  y=np.array(test_target),\n",
    "  num_epochs=1,\n",
    "  shuffle=False)\n",
    "\n",
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "\n",
    "print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))\n",
    "\n",
    "# Classify new flower samples.\n",
    "new_samples = np.array(\n",
    "  [[6.4, 3.2, 4.5, 1.5],\n",
    "   [5.8, 3.1, 5.0, 1.7],\n",
    "   [4.6, 3.4, 1.4, 0.3],\n",
    "   [5.9, 3.0, 5.1, 1.8]], dtype=np.float32)\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"x\": new_samples},\n",
    "  num_epochs=1,\n",
    "  shuffle=False)\n",
    "\n",
    "predictions = list(classifier.predict(input_fn=predict_input_fn))\n",
    "predicted_classes = [p[\"classes\"] for p in predictions]\n",
    "\n",
    "print(\n",
    "  \"New Samples, Class Predictions:    {}\\n\"\n",
    "  .format(predicted_classes))\n",
    "\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['versicolor', 'virginica', 'setosa', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array(predicted_classes).astype(int)\n",
    "flowers = ['setosa', 'versicolor', 'virginica']\n",
    "report = []\n",
    "\n",
    "for index, item in enumerate(predictions):\n",
    "    if(item == 0):\n",
    "        report.append('setosa') #flowers[0] \n",
    "    elif(item == 1):\n",
    "        report.append('versicolor') #flowers[1] \n",
    "    elif(item == 2):\n",
    "        report.append('virginica') #flowers[2]  \n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
