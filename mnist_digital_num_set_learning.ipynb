{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST data set learning using TensorFlow\n",
    "\n",
    "Guide link: https://www.tensorflow.org/get_started/mnist/beginners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Implementing model\n",
    "\n",
    "# Input value for TF running session. Would be a flatten image from MNIST dataset. 784 = 28x28 pixel image\n",
    "# placeholder - a value that we'll input when we ask TensorFlow to run a computation.\n",
    "x = tf.placeholder(tf.float32, [None, 784]) \n",
    "\n",
    "# Weight - zeros paramas: diamensional image vectors | 10-dimensional vectors represent number classes in range of 0-9\n",
    "W = tf.Variable(tf.zeros([784, 10])) \n",
    "\n",
    "b = tf.Variable(tf.zeros([10])) # Bias added to a to output\n",
    "\n",
    "# Create regression model using values above. \n",
    "y = tf.matmul(x, W) + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This set will be storing predictions\n",
    "# Each row is a one-hot 10-dimensional vector indicating which digit class \n",
    "# (zero through nine) the corresponding MNIST image belongs to.\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "\n",
    "# Cross entropy - the average length of communicating an event from one distribution \n",
    "# with the optimal code for another distribution. Ref.: http://colah.github.io/posts/2015-09-Visual-Information/\n",
    "\n",
    "# In this case, it will help to predict how close TF prediction of a number is to the actual correct answer.\n",
    "# Loss function indicates how bad the model's prediction was on a single example; \n",
    "# we try to minimize that while training across all the examples.\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "\n",
    "# Pick optimization algorithm.\n",
    "# GradientDescentOptimizer defines a rate at which TF is going to descend the cross entropy. \n",
    "# We set it to 0.5, but should be adjusted.\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# Create TF study session. Session is connecting to TF backend written in C++ to do heavy computation.\n",
    "# InteractiveSession is a convenient way to build cumputation graphs. If you not using InteractiveSession,\n",
    "# you will have to build \n",
    "sess = tf.InteractiveSession()\n",
    "# Initialize variables for TF\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# We are going to run training step 1000 times. Again, it should be adjusted for optimal learning time.\n",
    "for _ in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(50) # Picks 100 random data points from set. \n",
    "                                                   # More data TF algorithms use to train, better accuracy is produces.\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys}) # Run training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9155\n"
     ]
    }
   ],
   "source": [
    "# Evaluating model\n",
    "# Handpick correct predictions from y_ set\n",
    "# tf.argmax(y,1) is the label our model thinks is most likely for each input, \n",
    "# while tf.argmax(y_,1) is the true label.\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "# Evaluate accuracy on the test data\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# Print correct prediction rate \n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
